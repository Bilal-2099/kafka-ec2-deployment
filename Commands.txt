# Kafka Setup on Amazon Linux (EC2) using VS Code CLI

This document provides a clean, step-by-step guide to install and run **Apache Kafka with Zookeeper** on an **Amazon Linux EC2 instance**, using **VS Code SSH (Remote - SSH)**.

---

## Prerequisites

* Amazon Linux EC2 instance (running)
* Java installed
* VS Code with **Remote - SSH** extension
* EC2 Security Group allowing port **9092**

---

## Step 1: Connect EC2 to VS Code

Use VS Code **Remote - SSH** to connect to your EC2 instance.

---

## Step 2: Update System and Install Java

```bash
sudo yum update -y
sudo yum install java -y
java -version
```

---

## Step 3: Download and Install Kafka

Download Kafka (Scala 2.12, Kafka 3.8.1):

```bash
wget https://downloads.apache.org/kafka/3.8.1/kafka_2.12-3.8.1.tgz
ls
```

Extract and move Kafka:

```bash
tar -xzf kafka_2.12-3.8.1.tgz
sudo mv kafka_2.12-3.8.1 /usr/local/kafka
cd /usr/local/kafka/
```

---

## Step 4: Configure Kafka Broker

Edit Kafka configuration:

```bash
sudo nano config/server.properties
```

### Changes to Make

* Scroll down and **uncomment**:

```
advertised.listeners=PLAINTEXT://your-host
```

* Replace with your EC2 public IP:

```
advertised.listeners=PLAINTEXT://<EC2_PUBLIC_IP>:9092
```

Save and exit:

* **CTRL + S** → Save
* **CTRL + X** → Exit

---

## Step 5: Start Zookeeper

In **Terminal 1**:

```bash
cd /usr/local/kafka/
bin/zookeeper-server-start.sh config/zookeeper.properties
```

Zookeeper will start running.

---

## Step 6: Start Kafka Broker

Open **Terminal 2**:

```bash
ssh connect ec2 to vs code
export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M"
cd /usr/local/kafka/
bin/kafka-server-start.sh config/server.properties
```

(Optional – check running processes):

```bash
ps aux | grep zookeeper
ps aux | grep kafka
```

---

## Step 7: Create Kafka Topic & Producer

Open **Terminal 3**:

```bash
ssh connect ec2 to vs code
cd /usr/local/kafka/
```

Create topic:

```bash
bin/kafka-topics.sh --create \
--topic kafka_project \
--bootstrap-server <EC2_PUBLIC_IP>:9092 \
--replication-factor 1 \
--partitions 1
```

Start producer:

```bash
bin/kafka-console-producer.sh \
--topic kafka_project \
--bootstrap-server <EC2_PUBLIC_IP>:9092
```

---

## Step 8: Start Kafka Consumer

Open **Terminal 4**:

```bash
ssh connect ec2 to vs code
cd /usr/local/kafka/
bin/kafka-console-consumer.sh \
--topic kafka_project \
--bootstrap-server <EC2_PUBLIC_IP>:9092
```

Messages sent by producer will appear here.

---

## Step 9: Run Python Notebooks

⚠️ **Important:** Run each notebook in a **separate terminal**.

1. Run `KafkaProducer.ipynb`
2. Run `KafkaConsumer.ipynb`

---

## Step 10: Verify Output

* Check Kafka message flow
* Verify data in **S3 Bucket**

---

## Notes

* Replace `<EC2_PUBLIC_IP>` with your actual EC2 public IP
* Ensure port **9092** is open in EC2 Security Group
* Kafka and Zookeeper must remain running while producing/consuming

---

✅ Kafka setup completed successfully